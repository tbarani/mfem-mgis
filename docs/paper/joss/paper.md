---
title: 'MFEM-MGIS-MFRONT, a HPC mini-application targeting nonlinear thermo-mechanical simulations of nuclear fuels at mesoscale'
tags:
  - thermo-mechanical
  - HPC
  - mfem
  - nuclear fuel
authors:
  - name: Thomas Helfer
    orcid: 0000-0003-2460-5816
    affiliation: 1
  - name: Guillaume Latu
    orcid: 0000-0000-0000-0000
    affiliation: 1
  - name: Raphaël Prat
    orcid: 0009-0002-3808-5401
    affiliation: 1
  - name: Maxence Wangermez
    orcid: 0000-0002-3431-5081
    affiliation: 1
affiliations:
 - name: DES/IRESNE/DEC/SESC, CEA, France
   index: 1
date: 3 August 2023
bibliography: paper.bib
---

# Summary

The MFEM-MGIS-MFRONT application (abbreviated version MMM), aims at
efficiently use supercomputers in the field of implicit nonlinear
thermomechanics. This open-source library is based on several components as
prerequisites. The first component, `MFEM` [1,6], is a finite element library
designed for current supercomputers but also for the upcoming exascale
supercomputers. It provides many useful features for carrying out realistic
simulations: support for curvilinear meshes, high order approximation spaces
and different families of finite elements, interfaces to several types of
parallel solvers (including matrix-free ones), preconditioners, and native
support for adaptive non-conforming mesh refinement (AMR).  

## MFEM-based Thermo-Mechanical Solver for Nuclear Fuel Simulations

Originating from the applied mathematics and parallel computing communities, `MFEM` offers both
performance and a large panel of advanced mathematical features. In particular,
one can easily switch from one linear solver to another (direct or iterative),
which is essential for the targeted application: microstructure and mesoscale
modelling for nuclear fuel. However, applications to solid mechanics in `MFEM`
are mostly limited to simple constitutive equations such as elasticity and
hyperelasticity, which is insufficient. 

## Objectives

The aim of the `MMM` project is to
combine `MFEM` with the `MFrontGenericInterfaceSupport` (`MGIS`) project [4,8], an
open-source `C++` library that provides convenient data structures to support
arbitrarily complex nonlinear constitutive equations generated by the
open-source `MFront` code generator [2,5]. This library handles all the kinds of
behaviour supported by `MFront`. In the field of nonlinear mechanics, this
encompasses arbitrary complex behaviours that can describe damage, plasticity,
viscoplasticity, phase change in small and finite strain analyses. Generalised
behaviours such as strongly coupled thermomechanical behaviours, variational
approaches to fracture, Cosserat media are supported by `MGIS` and will be
considered in future versions of `MMM`. Thanks to the coupling with `MGIS` and
MFront and specific developments made, `MMM` has added the following mechanical
features compared to pure `MFEM` approach described in section Mechanics features.

The implementation of high order meshes or finite elements is easy.
The library tackles some peculiarities of nonlinear mechanics. In particular,
the support of complex constitutive laws and the management of advanced
boundary conditions.  The `MMM` library [7] is written in `C++-17` language and
provides a very high level of abstraction based on a very declarative
text-based Application Programming Interface. 

## Integrate MMM in an Open Source Ecosystem

The `MMM` library takes full advantage of an open-source software (OSS) stack. It
benefits from the increasing maturity of many communities and tools working
together. Thus, within `MFEM`, one has many available choices to set the linear
solver, such as: `Hypre`, `PETSc`, `MUMPS`, `SuperLU`, `UMFPACK` or other ones. Likewise,
several preconditioners, partitioning libraries, or input mesh formats can be
activated and used. Combinations are highly configurable and almost all
external libraries are switchable. To handle the numerous accessible
combinations, Spack is really a cornerstone. This package manager simplifies
building, installing, customizing, and sharing HPC software stacks. It provides
a simple way for installing packages with cumbersome structures and lots of
dependencies. `Spack` is an open-source package manager developed and maintained
by community of HPC developers. Our setup that combines OSS allows for a fast
and cheap access to advanced features embedded in the underlying libraries.

# Statement of needs

Minimal `MMM` requirements:
- `C++-17`
- `MFEM`
- `MGIS`
- `TFEL`(MFront)
- `MPI`
  
Optionals, depending on your MFEM installation:
- Solver or preconditionner:
	- `Hypre`
 	- `PETSc`
  	- `MUMPS`
  	- `SuperLU`
  	- `UMFPACK`
- Installation:
	- `Cmake`
	- `Spack`
 - Load Balancing:
 	- `Zoltan`
 	- `Metis`
    

# MFEM-MGIS in a nutshell

`MMM` has added the following mechanical features compared to pure `MFEM` approach: 

- Ability to handle several materials which distinct constitutive equations.  
- Support for internal state variables (defined at quadrature points):
	- Use of `MGIS` data structures
	- Use mechanical behavior laws genarated by MFront (DSL) 
- Support for complex boundary conditions specific to nonlinear mechanics:
	- Periodic evolution problems
 	- Dirichlet boundaries conditions 
- Support for post-processing specific to nonlinear mechanic:
	- computeMeanThermodynamicForcesValues: Compute the macroscopic stress and strain for each materials:
	- ParaviewExportIntegrationPointResultsAtNodes: Paraview post processing files with internal state variables according to `MGIS`
 	- ComputeResultantForceOnBoundary: TODO
- Flexible support to easily customize your problem:
	- Number of level of uniform refinement
   	- Element family and order
   	- Boundary conditions
   	- Solver and Preconditionner used

These features are described in the tutorial: `https://thelfer.github.io/mfem-mgis/web/tutorial.html`

# Numerical Results

Installation and deployment on desktop or large computers is based on the Spack
package manager [10]. With MMM, we were able to carry out a multi-material
elastic modelling on computing clusters. Scalability performance is good on a
few thousands of CPU cores. Despite the very high level of abstraction and the
genericness of MMM (multi-material and arbitrary behaviours), the overhead
appears reasonably limited, roughly 30% compared to a pure MFEM version which
provides very optimised and specialised kernels (this was tested on an elastic
setting with 2 materials). Several examples can be found on the open-source GitHub 
repository: `https://github.com/latug0/mfem-mgis-examples`. Below is a non-exhaustive 
list of examples running on supercomputers.

## Representative Elementary Volume (REV) of Combustible Mixed Oxides for Nuclear Applications:

 - Periodic boundaries conditions.
 - Impose evolution gradient for different materials.
 - Mesh is generated using `MEROPE` (https://github.com/MarcJos/Merope) and `GMSH`.
 - Elasto-viscoplastic behavior law
 - 17% of inclusions.
 - Simulation details :
 	- Around 10M of DoFs
 	- 1,024 `MPI` processes.
  	- 5 seconds (40 timesteps)
  	- Runtime : 1h32
 - Comparisons with results on FFT from paper "HOMOGENIZATION OF NONLINEAR VISCOELASTIC THREE-PHASE PARTICULATE COMPOSITES" 
 <figure>
<p align="center">
  <img
  src="Mox-picture.png"
  label="Mox-picture" alt="Evolution of macroscopic strain as a function of time for a simulation of a MOX containing 17% inclusion and using an elasto-viscoplastic law.">
  <figcaption> Visualization of a MOX with 17% inclusions, using an elasto-viscoplastic behavior law with color representation based on the magnitude of displacement denoted as "u." The figure includes the following: [1] A view of the Representative Elementary Volume (REV) of the MOX material. [2] A close-up view of a slide within the REV. [3] A view of the inclusions isolated from the matrix. [4] The evolution of macroscopic strain along the ZZ direction over time, comparing the results obtained with MMM and the reference data acquired by FFT. </figcaption>
</p>
 </figure>

## Modelling Fuel Pellet Fragmentation during Reactor start-up

- MicromorphicDamageII mechanical behavior MFront law
 <figure>
<p align="center">
  <img
  src="pellet.png"
  label="pellet" alt="Modelling fuel pellet fragmentation during reactor start-up">
  <figcaption>Modelling fuel pellet fragmentation during reactor start-up</figcaption>
</p>
 </figure>
 
## Viscoplastic behavior of a UO2 Polycrystal subjected to Uniaxial Compression Loading

- The mesh has been generated using `MEROPE`.


# Performance Results of Thermo-Mechanical Libraries on HPC plateforms"

Computation related to the behavior law at Gauss points is independent for each other, and while some behavior laws can be computationally expensive, the primary focus of parallel computation time is on solving linear systems at each time step. As a result, the parallel performance of our library is strongly influenced by the performance of MFEM (Finite Element Library) and, by extension, the selection of appropriate solvers and preconditioners.

Performance analysis framework:
- Strong scaling benchmark (`CEA/CCRT`) AMD Milan architecture until 65,000 cores.
- Only `MPI`.
- 80.10^6 degrees of freedoms (DoFs).
- REV 3D with an elasticity behavior law. Source code is available on the mfem-mgis-example github repository.
- Not enough load per sub-domain with 65k cores (less than 2k finite elements)

<figure>
  <img
  src="HPC_REV_Elasticity.png"
  label="HPCREVElasticity">
  <figcaption>Runtime of a simulation of a REV with an elasticity behvior law in 3D in function of the number of core (one core per MPI process) according to the couple preconditioner/solver chosen.</figcaption>
</figure>

# Conclusion

This paper presents the `MMM` HPC application designed to address large scale thermo-mechanical simulation and recent supercomputers. Based on an open-source
software stack, it allows for the fine representation of microstructure in full
3D in the field of fuel modelling. On the one hand, `MGIS` and `MFRONT` bring
nonlinear mechanics features such as damage, plasticity, viscoplasticity
capabilities. On the other hand, `MFEM` provides advanced finite elements schemes
and parallel performance (tested on several thousands of cores until now).
Open-source approach was chosen mainly to: promote collaboration, improve
reproducibility, and reduce costs for development and maintenance.

# Citations



# help


## Objectives of MFEM-MGIS-MFRONT mini-application


## Motivations for an open-source framework

 At
the beginning of MMM mini-app, a preliminary study considering several
potential finite element libraries leads us to the conclusion that choosing the
right open-source stack was a key point. For example, to achieve both
performance and keep low maintenance/development costs, one should ensure that
components of the software stack can connect well with each other, and offer a
high degree of controllability. One must also looks at the maturity of each
library and the quality of technical support proposed. The responsiveness of
the support is important and is often related to the size of the community
behind each software. Coding practices, documentation and expected durability
of the libraries have also to be considered. Then, pondering all these points
in our analysis, assessing the risks and in estimating the potential gains, we
chose the most suitable software stack serving our purpose.  Compared to closed
source development that we might have considered, OSS brings regular bug
fixing, peer review of code by many developers, a community that tests and
improves the software frequently. The proposed services such as error
reporting, bug tracker, forum for user requests and offered support help a lot
for speeding up the development process and shortening maintenance actions.
High-performance simulations suffer from difficulties for ensuring exact
numerical reproducibility. Numerical results that are not reproducible make it
difficult to assess the methods and novelties a given software produces. In
addition to that, the available publications typically lack the level of detail
that is required to reproduce simulations. Also, with prototype realizations
often remaining private, other people are unable to track the code. Then, one
should find ways to improve this issue. Several reasons explains why
reproducibility is difficult: floating-point arithmetic peculiarities,
non-determinism of parallel calculations, complex software stacks, closed
source software. The two first points are well beyond the scope of this
contribution. However, the last two points can be partially solved with
open-source solutions. Hence, assembling software, connecting tools together
into pipelines, and specifying parameters can be handled. Existing tools can
automate a series of processes. For MMM, we choose to rely on Spack to
completely organize and setup the versions of the different libraries composing
the stack. Furthermore, the CMake tool helped us to achieve reproducible builds
across multiple computers and systems. A set of reference solutions has also
been designed. Then, we can check on any new target machine if MMM gives
correct results using Spack and CMake. Verification through defined standard
examples ensure quite fast deployment, these examples also serve as
documentation for users of the code. It is also foreseen that we supplement the
current strategy with a continuous integration platform to further improve the
robustness of the mini-app.

Open-source approach enable transparency, accessibility, and replicability
among contributors of a single code. Modelling effort can include participants
with different domain expertise. This diversity of contributions really helps
building up software that combine state-of-the-art numerical methods.  Our goal
is to establish international collaborations with privileged partners and with
academics around MMM. In this context, open-source approach is fostering a
greater adoption of the software product. We also expect that this solution can
favour external contributions and promote collaborations focusing on grain and
subgrain-resolved microstructure for nuclear fuel modelling.

## Numerical results
The presentation will show some of the current
capabilities of the software.

[12] CEA and EDF. Salomé platform [Software]. URL: https://www.salome-platform.org/user-section/about/med 


